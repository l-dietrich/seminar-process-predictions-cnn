{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/l-dietrich/seminar-process-predictions-cnn/blob/main/cnn_pm_seminar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PRd9bYA8f1c"
      },
      "outputs": [],
      "source": [
        "!pip install pm4py==2.2.32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZyPa39z80dy"
      },
      "outputs": [],
      "source": [
        "from functools import reduce\n",
        "import pandas as pd\n",
        "import pm4py\n",
        "import numpy as np\n",
        "from enum import Enum\n",
        "from datetime import timedelta, date, datetime\n",
        "from math import floor\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset, Subset\n",
        "from torchsummary import summary\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o10odk-JN-PY"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Is CUDA supported by this system? {torch.cuda.is_available()}\")\n",
        "print(f\"CUDA version: {torch.version.cuda}\")\n",
        "\n",
        "if(torch.cuda.is_available()):\n",
        "  cuda_id = torch.cuda.current_device()\n",
        "  print(f\"ID of current CUDA device: {torch.cuda.current_device()}\")\n",
        "          \n",
        "  print(f\"Name of current CUDA device: {torch.cuda.get_device_name(cuda_id)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HQu4BWxF88XO"
      },
      "outputs": [],
      "source": [
        "# event_log = pm4py.read_xes(\"./helpdesk.xes\")\n",
        "# event_log = pm4py.read_xes(\"bpic_12_a.xes\")\n",
        "# event_log = pm4py.read_xes(\"bpic_12_o.xes\")\n",
        "event_log = pm4py.read_xes(\"bpic_12_w.xes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "molWbY9NVfiQ"
      },
      "outputs": [],
      "source": [
        "print(f\"End Activties (w/o artifical END activtiy): {pm4py.get_end_activities(event_log)}\")\n",
        "\n",
        "end_activity = 'END'\n",
        "\n",
        "for trace in event_log:\n",
        "  end_event = pm4py.objects.log.obj.Event()\n",
        "  end_event['concept:name'] = end_activity\n",
        "  end_event['time:timestamp'] = trace[-1]['time:timestamp']\n",
        "  trace.append(end_event)\n",
        "\n",
        "activity_domain = list(pm4py.get_event_attribute_values(event_log, \"concept:name\").keys())\n",
        "activity_domain.sort()\n",
        "print(f\"Activity Domain: {activity_domain}\")\n",
        "print(f\"Start Activites: {pm4py.get_start_activities(event_log)}\")\n",
        "print(f\"End Activties:   {pm4py.get_end_activities(event_log)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Cy2AH-Ur-hOA"
      },
      "outputs": [],
      "source": [
        "def trace_vector(get_performance, trace, activity_domain=[]):\n",
        "  if len(activity_domain) == 0:\n",
        "    if len(trace) == 0:\n",
        "      raise Exception(\"For empty traces an non-empty activity domain has to be specified.\")\n",
        "    activity_domain = list(set(trace))\n",
        "  vec = np.zeros(len(activity_domain), dtype=np.float32)\n",
        "  activity_trace = list(map(lambda event: event['concept:name'], trace))\n",
        "  if(get_performance): \n",
        "    trace_start = date.min\n",
        "    for index, event in enumerate(trace):\n",
        "      if index == 0:\n",
        "        trace_start = event['time:timestamp']\n",
        "      else:\n",
        "        index = activity_domain.index(event['concept:name'])\n",
        "        vec[index] = (event['time:timestamp'] - trace_start).total_seconds()/(24*60*60)\n",
        "  else:\n",
        "    for index, activity in enumerate(activity_domain):\n",
        "      vec[index] = activity_trace.count(activity)\n",
        "  return vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEJEbFZjMqfg"
      },
      "source": [
        "# Eventlog Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LUO7MYf5IXic"
      },
      "outputs": [],
      "source": [
        "class EventLogDataset(Dataset):\n",
        "  def __init__(self, event_log, activity_domain, transform=None, target_transform=None, min_prefix_size = 2):\n",
        "    self.event_log = event_log\n",
        "    self.activity_domain = activity_domain\n",
        "    self.transform = transform\n",
        "    self.target_transform = target_transform\n",
        "    self.prefix_traces = [] \n",
        "    self.images = []\n",
        "    self.labels = []\n",
        "    self.trace_idx = {}\n",
        "    for trace in event_log:\n",
        "      if len(trace) > min_prefix_size + 1:\n",
        "        prefix_closure = [trace[:i+1] for i in range(len(trace))] \n",
        "        for i in range(min_prefix_size, len(prefix_closure)): # Skip prefixes smaller than min_prefix_size\n",
        "          self.prefix_traces.append(prefix_closure[i-1])\n",
        "          prefix_parikh_vec = np.vstack([trace_vector(False, prefix, self.activity_domain) for prefix in prefix_closure[:i]])\n",
        "          prefix_performance_vec = np.vstack([trace_vector(True, prefix, self.activity_domain) for prefix in prefix_closure[:i]])\n",
        "          self.images.append(np.stack([prefix_parikh_vec, prefix_performance_vec], axis=0))\n",
        "\n",
        "          label = trace[i]['concept:name']\n",
        "          label = activity_domain.index(label)\n",
        "          self.labels.append(label)\n",
        "\n",
        "          # Add trace index to map for finding original full traces \n",
        "          if(i == len(prefix_closure) - 1):\n",
        "            self.trace_idx[trace.attributes['concept:name']] = len(self.labels) - 1\n",
        "\n",
        "    self.max_image_shape = max(map(np.shape, self.images))\n",
        "\n",
        "    # pad images to have same size and cast to tensor\n",
        "    for index, image in enumerate(self.images):\n",
        "      padding_size = self.max_image_shape[1] - image.shape[1]\n",
        "      self.images[index] = np.pad(\n",
        "          image, \n",
        "          [(0, 0), (padding_size, 0), (0, 0)],\n",
        "          mode='constant',\n",
        "          constant_values=0\n",
        "      )\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.labels)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    image = self.images[idx]\n",
        "    label = self.labels[idx]\n",
        "    if self.transform:\n",
        "      image = self.transform(image)\n",
        "    if self.target_transform:\n",
        "      label = self.target_transform(label)\n",
        "    return image, label\n",
        "  \n",
        "  def to(self, device):\n",
        "    self.images = torch.tensor(self.images, device = device)\n",
        "    self.labels = torch.tensor(self.labels, device = device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_yFNy7DlMk0"
      },
      "source": [
        "# CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Y98V7tNaL-uy"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "activity_domain = list(pm4py.get_event_attribute_values(event_log, \"concept:name\").keys())\n",
        "activity_domain.sort()\n",
        "\n",
        "dataset = EventLogDataset(event_log, activity_domain)\n",
        "dataset.to(device)\n",
        "\n",
        "train_size = floor(len(dataset) * 2/3)\n",
        "train_dataset = Subset(dataset, range(0, train_size))\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "test_size = len(dataset) - train_size\n",
        "test_dataset = Subset(dataset, range(train_size, train_size + test_size))\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "s2xt-0AGlDeV"
      },
      "outputs": [],
      "source": [
        "class NextActivityModel(nn.Sequential):\n",
        "  def __init__(self, image_shape):\n",
        "    super(NextActivityModel, self).__init__()\n",
        "\n",
        "    def _dim_reduction_per_pooling(dim):\n",
        "          return floor((dim - 2) / 2) + 1\n",
        "\n",
        "\n",
        "    c_in, h_in, w_in = image_shape #channels, height, width\n",
        "    c_out, h_out, w_out = 16, h_in, w_in\n",
        "    kernel_size = 1\n",
        "    \n",
        "\n",
        "    for i in range(3):\n",
        "      if (\n",
        "          _dim_reduction_per_pooling(h_out) > 0 and \n",
        "          _dim_reduction_per_pooling(w_out) > 0):\n",
        "        c_out = c_out * 2\n",
        "        kernel_size = kernel_size * 2\n",
        "        self.append(nn.Conv2d(c_in, c_out, kernel_size, padding='same'))\n",
        "        c_in = c_out\n",
        "        self.append(nn.BatchNorm2d(c_out))\n",
        "        h_out = _dim_reduction_per_pooling(h_out)\n",
        "        w_out = _dim_reduction_per_pooling(w_out)\n",
        "        self.append(nn.ReLU())\n",
        "        self.append(nn.MaxPool2d(2, 2))\n",
        "      else:\n",
        "        break\n",
        "\n",
        "    self.append(nn.Flatten(start_dim=1))\n",
        "    self.append(nn.Linear(c_out * h_out * w_out, w_in))\n",
        "    self.append(nn.Softmax(dim=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uG4_tCx9MEFP"
      },
      "outputs": [],
      "source": [
        "model = NextActivityModel(dataset.max_image_shape).to(device)\n",
        "summary(model, dataset.max_image_shape, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EHSSEAf-1mnF"
      },
      "outputs": [],
      "source": [
        "def accuracy(outputs, labels):\n",
        "    preds = torch.argmax(outputs, dim=1)\n",
        "    return torch.sum(preds == labels).div(len(preds)).item()\n",
        "\n",
        "def training_epoch(dataloader, model, loss_fn, optimizer):\n",
        "  running_loss = 0. \n",
        "  last_loss = 0.\n",
        "\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "      # Compute prediction and loss\n",
        "      pred = model(X)\n",
        "      loss = loss_fn(pred, y)\n",
        "\n",
        "      # Backpropagation\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # Gather data\n",
        "      running_loss += loss.item()\n",
        "      if batch % 10 == 9:\n",
        "          last_loss = running_loss / 9 # loss per batch\n",
        "          print('\\t batch {} loss: {}'.format(batch + 1, last_loss))\n",
        "          running_loss = 0.\n",
        "  return last_loss\n",
        "\n",
        "def test_epoch(dataloader, model, loss_fn):\n",
        "  loss = 0\n",
        "  acc = 0\n",
        "  for X, y in dataloader:\n",
        "    outputs = model(X)\n",
        "    loss += criterion(outputs, y).item()\n",
        "    acc += accuracy(outputs, y)\n",
        "\n",
        "  return loss/len(dataloader), acc/len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3fY6gV9HbGQ"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 100\n",
        "PATIENCE = 5\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=2E-4, weight_decay= 4E-4)\n",
        "history = pd.DataFrame(columns=[\"Training Loss\",\"Test Loss\",\"Training Accuracy\",\"Test Accuracy\"])\n",
        "\n",
        "best_test_loss = math.inf\n",
        "iterations_since_best_test_loss = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Epoch {epoch + 1}\")\n",
        "    print(\"-\" * 30)\n",
        "    \n",
        "    model.train(True)\n",
        "    avg_train_loss = training_epoch(train_loader, model, criterion, optimizer)\n",
        "    model.train(False)\n",
        "\n",
        "    train_acc = 0\n",
        "    for X, y in train_loader:\n",
        "      train_acc += accuracy(model(X), y)\n",
        "    train_acc = train_acc / len(train_loader)\n",
        "\n",
        "    avg_test_loss, test_acc = test_epoch(test_loader, model, criterion)\n",
        "    history.loc[len(history)] = [avg_train_loss, avg_test_loss, train_acc, test_acc]\n",
        "\n",
        "    print('LOSS\\t train {} \\t test {}'.format(avg_train_loss, avg_test_loss))\n",
        "    print('ACC \\t train {} \\t test {}'.format(train_acc, test_acc))\n",
        "\n",
        "    if avg_test_loss < best_test_loss:\n",
        "      best_test_loss = avg_test_loss\n",
        "      iterations_since_best_test_loss = 0\n",
        "    else:\n",
        "      if iterations_since_best_test_loss > PATIENCE:\n",
        "        print(f'Stopping early as test loss has not improved for {PATIENCE} iterations')\n",
        "        break\n",
        "      else:\n",
        "        iterations_since_best_test_loss += 1\n",
        "\n",
        "print(\"Training Done!\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  model.to(\"cpu\")\n",
        "  dataset.to(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEtl82UDud1U"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8ngAAtSQrkx"
      },
      "outputs": [],
      "source": [
        "history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agbHp9g9GDtl"
      },
      "outputs": [],
      "source": [
        "sns.lineplot(data=history[[\"Training Loss\",\"Test Loss\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOQ9N5TX7HV7"
      },
      "outputs": [],
      "source": [
        "sns.lineplot(data=history[[\"Training Accuracy\",\"Test Accuracy\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qc4hdzKtatDw"
      },
      "outputs": [],
      "source": [
        "sns.histplot(list(map(lambda i: activity_domain[i][:min(len(activity_domain[i]),10)],dataset.labels)))\n",
        "plt.xlabel(\"Prediction Target\")\n",
        "plt.xticks(rotation=45)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "arB1P8usaxUN"
      },
      "outputs": [],
      "source": [
        "outputs = model(dataset.images)\n",
        "pred = torch.argmax(outputs, dim=1)\n",
        "\n",
        "cf_matrix = confusion_matrix(dataset.labels, pred, labels=range(len(activity_domain)))\n",
        "df_cm = pd.DataFrame(cf_matrix, index = [i for i in activity_domain],\n",
        "                     columns = [i for i in activity_domain])\n",
        "print(accuracy(outputs, dataset.labels))\n",
        "df_cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zu6y3U5lZ7Gm"
      },
      "outputs": [],
      "source": [
        "print(classification_report(dataset.labels, pred, labels=range(len(activity_domain)), target_names=activity_domain))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "mount_file_id": "17wesDCFZQtaQu8w3bXm0xHnjDxW0xY3e",
      "authorship_tag": "ABX9TyMLvJFYzLGw1cGnu7Ad3Bd6",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
